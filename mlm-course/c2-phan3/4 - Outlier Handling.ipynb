{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3906151",
   "metadata": {},
   "source": [
    "# Outlier Handling\n",
    "“The Outlier is an observation that deviates so much from other observations as to raise suspicion that it is produced by another mechanism.” [D. Hawkins. Identification of Outliers, Chapman and Hall, 1980].\n",
    "\n",
    "Statistical factors such as mean and variance are easily affected by outliers. Additionally, some machine learning models are sensitive to outliers that can degrade their quality. Therefore, we often remove outliers from variables depending on the algorithm we want to train.\n",
    "\n",
    "We have discussed how to identify outliers. And in this section, we will discuss how to handle them to train machine learning models.\n",
    "\n",
    "### How to preprocess outlier?\n",
    "+ Trimming: remove outliers from the data set.\n",
    "+ Treat outliers as missing data and proceed with any missing data assignment technique.\n",
    "+ Discretization: outliers are replaced in border bins along with higher or lower values of the distribution.\n",
    "+ Censoring: limits the variable distribution to the max/min value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2237611",
   "metadata": {},
   "source": [
    "# 1. Trimming/Truncation\n",
    "Trimming/Truncation involves removing outliers from the data set. We just need to decide on a measurement to determine the outlier. This could be the Gaussian approximation for normally distributed variables or the IQR asymptotic rule for skewed variables.\n",
    "\n",
    "### Gaussian approximation rule:\n",
    "<img src=\"img/j1.png\" width=700/>\n",
    "\n",
    "### Quantile approximation rule:\n",
    "<img src=\"img/j2.png\" width=700/>\n",
    "\n",
    "### IQR asymptotic rule:\n",
    "<img src=\"img/j3.png\" width=680/>\n",
    "\n",
    "#### Advantage\n",
    "+ Fast\n",
    "#### Limit\n",
    "+ Outliers for one variable may contain useful information in other variables.\n",
    "+ We can eliminate most of the data set if there are outliers in many variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb59837",
   "metadata": {},
   "source": [
    "# 2. Censoring/Capping.\n",
    "Censoring or Capping is the max/min limit of the distribution at any value. In other words, values larger or smaller than arbitrarily determined values are censored.\n",
    "\n",
    "Capping can be done at both ends or one end of the distribution depending on the variable and the user.\n",
    "\n",
    "Numbers to limit the distribution can identify:\n",
    "+ Optional\n",
    "+ Use the IQR proximity rule\n",
    "+ Use the Gaussian approximation\n",
    "+ Use quantile\n",
    "#### Advantage:\n",
    "+ Does not remove data\n",
    "#### Limit:\n",
    "+ Distort the variable's distributions\n",
    "+ Distort the relationship between variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5292105e",
   "metadata": {},
   "source": [
    "# 3. Feature Scaling\n",
    "\n",
    "We discussed earlier that feature rates are quite important when building machine learning models. Specifically:\n",
    "\n",
    "\n",
    "### Feature magnitude is important because:\n",
    "\n",
    "- The regression coefficients of the linear model are directly affected by the proportional transformation of the variable.\n",
    "- Variables with larger magnitude/range of values will outperform variables with smaller magnitude/range of values.\n",
    "- Gradient descent converges faster when the features have the same scale.\n",
    "- Feature elasticity helps reduce the time to find support vectors for SVM.\n",
    "- Euclidean distance is sensitive to the magnitude of the feature.\n",
    "- Some algorithms such as PAC require features to be concentrated at 0.\n",
    "\n",
    "\n",
    "### Machine learning models are directly affected by characteristic scaling:\n",
    "\n",
    "- Linear Regression and Logistic Regression\n",
    "- Neural network\n",
    "- Support vector machine (SVM)\n",
    "- KNN\n",
    "- K-means clustering\n",
    "- Linear discriminant analysis (LDA)\n",
    "- Principal component analysis (PCA)\n",
    "\n",
    "\n",
    "### Characteristic elasticity\n",
    "\n",
    "**Feature scaling** refers to methods or techniques of normalizing the range of independent variables in the data or in other words, methods of placing the range of characteristic values within the same scaling rule. Feature scaling is often the final step in the data preprocessing pipeline, performed **just before training machine learning algorithms**.\n",
    "\n",
    "  We will discuss some typical Elastication techniques:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90429e77",
   "metadata": {},
   "source": [
    "### 1. Standardization (Z-score normalization):\n",
    "Centers the variable at 0 and set the variance to 1, the procedure is:\n",
    "$$ X' = \\frac{X - mean(X)}{Std(X)} $$\n",
    "$$$$\n",
    "\n",
    "The result of the transformation is z, referred to as the z-score, which indicates the standard deviation by which a particular observation deviates from the mean. The z-score determines the position of an observation in a distribution (in terms of the number of standard deviations from the mean of the distribution). The sign of the z-score (+ or -) indicates whether the observation is above (+) or below (-) the mean.\n",
    "\n",
    "<img src=\"img/k1.png\" width=650/>\n",
    "\n",
    "#### In short, standardization:\n",
    "1. **Centres the mean at 0.**\n",
    "2. **Scales the variance at 1.**\n",
    "3. **Preserves the shape of the original distribution.**\n",
    "4. **Minimum and maximum values vary.**\n",
    "5. **Preserves outliers.**\n",
    "\n",
    "#### When to use:\n",
    "1. **It’s useful when there are a few outliers, but not so extreme that you need clipping (When the feature distribution does not contain extreme outliers)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e891ae73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data Statistics:\n",
      "Mean = 79.09\n",
      "Std = 50.88\n",
      "\n",
      "\n",
      "\n",
      "After use Z-score normalize:\n",
      "\n",
      "     Price Sign  Price_scaled\n",
      "0     100    +          0.43\n",
      "1      90    +          0.22\n",
      "2      50    -         -0.60\n",
      "3      40    -         -0.81\n",
      "4      20    -         -1.22\n",
      "5     100    +          0.43\n",
      "6      50    -         -0.60\n",
      "7      60    -         -0.39\n",
      "8     120    +          0.84\n",
      "9      40    -         -0.81\n",
      "10    200    +          2.49 \n",
      "\n",
      "Mean = -0.00\n",
      "Std = 1.05\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data = {'Price': [100, 90, 50, 40, 20, 100, 50, 60, 120, 40, 200]}\n",
    "df = pd.DataFrame(data)\n",
    "df['Sign'] = df['Price'].apply(lambda x: \"+\" if x > df[\"Price\"].mean() else \"-\")\n",
    "\n",
    "# Print mean and std before scaling\n",
    "print(\"Original Data Statistics:\")\n",
    "print(f'Mean = {df[\"Price\"].mean():.2f}')\n",
    "print(f'Std = {df[\"Price\"].std():.2f}\\n')\n",
    "\n",
    "scaler = StandardScaler().fit(df[['Price']])\n",
    "\n",
    "# Transform and round the scaled data\n",
    "df['Price_scaled'] = scaler.transform(df[['Price']])\n",
    "df['Price_scaled'] = df['Price_scaled'].round(2)\n",
    "\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"\\n\\nAfter use Z-score normalize:\\n\\n\", df, \"\\n\")\n",
    "\n",
    "# Print mean and std after scaling\n",
    "print(f'Mean = {df[\"Price_scaled\"].mean():.2f}')\n",
    "print(f'Std = {df[\"Price_scaled\"].std():.2f}\\n')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f409fb9f",
   "metadata": {},
   "source": [
    "### 2. Min/max scaling - MinMaxScaling:\n",
    "Scales the variable between 0 and 1, the procedure is:\n",
    "$$ X' = \\frac{X - min(X)}{max(X) - min(X)}$$\n",
    "$$$$\n",
    "\n",
    "MinMaxScaling is a data normalization technique that transforms the values of variables into a specific range, usually [0, 1]. This method helps synchronize variables with different units of measurement and ensures that they are all within a pre-selected value range.\n",
    "\n",
    "#### In short, MinMaxScaling:\n",
    "1. **Minimum and maximum values within [0, 1].**\n",
    "2. **Mean varies.**\n",
    "3. **Variance varies.**\n",
    "4. **Preserves outliers.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19f33dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data Statistics:\n",
      "Min = 20.00\n",
      "Max = 200.00\n",
      "\n",
      "\n",
      "\n",
      "After use MinMax_Scaling::\n",
      "\n",
      "     Price  Price_scaled\n",
      "0     100          0.44\n",
      "1      90          0.39\n",
      "2      50          0.17\n",
      "3      40          0.11\n",
      "4      20          0.00\n",
      "5     100          0.44\n",
      "6      50          0.17\n",
      "7      60          0.22\n",
      "8     120          0.56\n",
      "9      40          0.11\n",
      "10    200          1.00 \n",
      "\n",
      "Min = 0.00\n",
      "Max = 1.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "data = {'Price': [100, 90, 50, 40, 20, 100, 50, 60, 120, 40, 200]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Print mean and std before scaling\n",
    "print(\"Original Data Statistics:\")\n",
    "print(f'Min = {df[\"Price\"].min():.2f}')\n",
    "print(f'Max = {df[\"Price\"].max():.2f}\\n')\n",
    "\n",
    "scaler = MinMaxScaler().fit(df[['Price']])\n",
    "\n",
    "# Transform and round the scaled data\n",
    "df['Price_scaled'] = scaler.transform(df[['Price']])\n",
    "df['Price_scaled'] = df['Price_scaled'].round(2)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"\\n\\nAfter use MinMax_Scaling::\\n\\n\", df, \"\\n\")\n",
    "\n",
    "# Print mean and std after scaling\n",
    "print(f'Min = {df[\"Price_scaled\"].min():.2f}')\n",
    "print(f'Max = {df[\"Price_scaled\"].max():.2f}\\n')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0179bad1",
   "metadata": {},
   "source": [
    "### 3. Mean normalization:\n",
    "Centres the variable at 0 and re-scaled the variable to the value range\n",
    "$$ X_{normalized} = \\frac{X - mean(X)}{max(X) - min(X)}$$\n",
    "$$$$\n",
    "\n",
    "#### In short, mean normalization:\n",
    "1. **Centres the mean at 0**\n",
    "2. **Minimum and maximum values within [0, 1].**\n",
    "3. **Variance varies.**\n",
    "4. **Preserves outliers.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7c0b409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data Statistics:\n",
      "Mean = 79.09\n",
      "Std = 50.88\n",
      "\n",
      "\n",
      "\n",
      "After use Mean_Scaling:\n",
      "\n",
      "     Price Sign  Price_scaled\n",
      "0     100    +         20.91\n",
      "1      90    +         10.91\n",
      "2      50    -        -29.09\n",
      "3      40    -        -39.09\n",
      "4      20    -        -59.09\n",
      "5     100    +         20.91\n",
      "6      50    -        -29.09\n",
      "7      60    -        -19.09\n",
      "8     120    +         40.91\n",
      "9      40    -        -39.09\n",
      "10    200    +        120.91 \n",
      "\n",
      "Mean = 0.00\n",
      "Std = 50.88\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data = {'Price': [100, 90, 50, 40, 20, 100, 50, 60, 120, 40, 200]}\n",
    "df = pd.DataFrame(data)\n",
    "df['Sign'] = df['Price'].apply(lambda x: \"+\" if x > df[\"Price\"].mean() else \"-\")\n",
    "\n",
    "# Print mean and std before scaling\n",
    "print(\"Original Data Statistics:\")\n",
    "print(f'Mean = {df[\"Price\"].mean():.2f}')\n",
    "print(f'Std = {df[\"Price\"].std():.2f}\\n')\n",
    "\n",
    "scaler = StandardScaler(with_mean=True, with_std=False).fit(df[['Price']])\n",
    "\n",
    "# Transform and round the scaled data\n",
    "df['Price_scaled'] = scaler.transform(df[['Price']])\n",
    "df['Price_scaled'] = df['Price_scaled'].round(2)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"\\n\\nAfter use Mean_Scaling:\\n\\n\", df, \"\\n\")\n",
    "\n",
    "# Print mean and std after scaling\n",
    "print(f'Mean = {df[\"Price_scaled\"].mean():.2f}')\n",
    "print(f'Std = {df[\"Price_scaled\"].std():.2f}\\n')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91d5d52",
   "metadata": {},
   "source": [
    "### 4. Scaling to the absolute maximum value - MaxAbsScaling\n",
    "Scales the variable between in range [-1, 1]:\n",
    "$$ X' = \\frac{X}{max(|X|)}$$\n",
    "$$$$\n",
    "\n",
    "#### In short, MaxAbsScaling:\n",
    "1. **Mean not centred.**\n",
    "2. **Variance not scaled.**\n",
    "3. **Scikit-learn recommends use with:**\n",
    "    + Data that is centred\n",
    "    + Sparse matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd44da21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data Statistics:\n",
      "Max = 200\n",
      "Min = 20\n",
      "\n",
      "\n",
      "\n",
      "After MaxAbs_Scaling:\n",
      "\n",
      "     Price  Price_scaled\n",
      "0     100          0.50\n",
      "1      90          0.45\n",
      "2      50          0.25\n",
      "3      40          0.20\n",
      "4      20          0.10\n",
      "5     100          0.50\n",
      "6      50          0.25\n",
      "7      60          0.30\n",
      "8     120          0.60\n",
      "9      40          0.20\n",
      "10    200          1.00 \n",
      "\n",
      "Max = 1.0\n",
      "Min = 0.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "data = {'Price': [100, 90, 50, 40, 20, 100, 50, 60, 120, 40, 200]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Print max and min before scaling\n",
    "print(\"Original Data Statistics:\")\n",
    "print(f'Max = {df[\"Price\"].max()}')\n",
    "print(f'Min = {df[\"Price\"].min()}\\n')\n",
    "\n",
    "# Perform MaxAbs scaling using MaxAbsScaler\n",
    "scaler = MaxAbsScaler().fit(df[['Price']])\n",
    "df['Price_scaled'] = scaler.transform(df[['Price']])\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"\\n\\nAfter MaxAbs_Scaling:\\n\\n\", df, \"\\n\")\n",
    "\n",
    "# Print max and min after MaxAbs scaling\n",
    "print(f'Max = {df[\"Price_scaled\"].max()}')\n",
    "print(f'Min = {df[\"Price_scaled\"].min()}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0aa6482",
   "metadata": {},
   "source": [
    "### 5. Scaling to median and quantiles - RobustScaling\n",
    "$$ X' = \\frac{X - median(X)}{75th\\_quant(X) - 25th\\_quant(X)}$$\n",
    "$$$$\n",
    "\n",
    "\n",
    "#### In short, RobustScaling:\n",
    "1. **Median centred at zero.**\n",
    "2. **Handles outliers.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eef38920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data Statistics:\n",
      "Median = 60.0\n",
      "Q25 = 45.0\n",
      "Q75 = 100.0\n",
      "IQR = Q75 - Q25 = 55.0\n",
      "\n",
      "\n",
      "\n",
      "After Robust_Scaling:\n",
      "\n",
      "     Price  Price_scaled\n",
      "0     100      0.727273\n",
      "1      90      0.545455\n",
      "2      50     -0.181818\n",
      "3      40     -0.363636\n",
      "4      20     -0.727273\n",
      "5     100      0.727273\n",
      "6      50     -0.181818\n",
      "7      60      0.000000\n",
      "8     120      1.090909\n",
      "9      40     -0.363636\n",
      "10    200      2.545455\n",
      "\n",
      "Median = 0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "data = {'Price': [100, 90, 50, 40, 20, 100, 50, 60, 120, 40, 200]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Print median and IQR before scaling\n",
    "print(\"Original Data Statistics:\")\n",
    "print(f'Median = {df[\"Price\"].median()}')\n",
    "print(f'Q25 = {np.percentile(df[\"Price\"], 25)}')\n",
    "print(f'Q75 = {np.percentile(df[\"Price\"], 75)}')\n",
    "print(f'IQR = Q75 - Q25 = {np.percentile(df[\"Price\"], 75) - np.percentile(df[\"Price\"], 25)}\\n')\n",
    "\n",
    "# Perform Robust scaling using RobustScaler\n",
    "scaler = RobustScaler().fit(df[['Price']])\n",
    "df['Price_scaled'] = scaler.transform(df[['Price']])\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"\\n\\nAfter Robust_Scaling:\\n\\n\", df)\n",
    "print(f'\\nMedian = {np.median(df[\"Price_scaled\"])}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf2a762",
   "metadata": {},
   "source": [
    "### 6. Scaling to  vector unit  length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30c9184",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "87ed4d6f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

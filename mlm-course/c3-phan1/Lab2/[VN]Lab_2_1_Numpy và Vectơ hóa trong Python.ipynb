{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "WdRg6klznfvQ"
   },
   "source": [
    "Lab này sẽ giới thiệu ngắn gọn về Python. Ngay cả khi bạn đã sử dụng Python trước đó, điều này sẽ giúp bạn làm quen với các hàm mà chúng ta sẽ cần.\n",
    "\n",
    "**Hướng dẫn:**\n",
    "- Chúng ta sẽ sử dụng Python 3.\n",
    "- Tránh sử dụng vòng lặp for và vòng lặp while, trừ khi được yêu cầu rõ ràng làm như vậy.\n",
    "- Sau khi mã hóa hàm của bạn, hãy chạy cell ngay bên dưới để kiểm tra xem kết quả của bạn có đúng không.\n",
    "\n",
    "**Sau lab này, chúng ta sẽ:**\n",
    "- Có thể sử dụng iPython Notebook\n",
    "- Có thể dùng các hàm numpy và các phép toán ma trận/vectơ numpy\n",
    "- Hiểu được khái niệm \"broadcasting\"\n",
    "- Có thể vectơ hóa code\n",
    "\n",
    "Hãy bắt đầu nào!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "P811HWD8nfvS"
   },
   "source": [
    "## Về iPython Notebook ##\n",
    "\n",
    "iPython Notebooks là môi trường mã hóa tương tác được nhúng trong một trang web. Bạn sẽ sử dụng iPython notebook trong lab này. Bạn chỉ cần viết code giữa chú thích ### BẮT ĐẦU CODE Ở ĐÂY ### và ### KẾT THÚC CODE Ở ĐÂY ###. Sau khi viết code, bạn có thể chạy cell bằng cách nhấn \"SHIFT\"+\"ENTER\" hoặc nhấp vào \"Run Cell\" (được biểu thị bằng biểu tượng) ở thanh trên của notebook.\n",
    "\n",
    "Chúng ta thường chỉ định \"(≈ X dòng code)\" trong các chú thích để cho bạn biết bạn cần viết bao nhiêu code. Đó chỉ là một ước tính sơ bộ, vì vậy đừng cảm thấy tồi tệ nếu code của bạn dài hoặc ngắn hơn.\n",
    "\n",
    "**Task 1**: Đặt test thành `\"Hello World\"` trong cell bên dưới để in \"Hello World\" và chạy hai cell bên dưới."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "r1Njdj-0nfvS"
   },
   "outputs": [],
   "source": [
    "### BẮT ĐẦU CODE Ở ĐÂY ### (≈ 1 dòng code)\n",
    "test = \"Hello World\"\n",
    "### KẾT THÚC CODE Ở ĐÂY ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "QxH1MobmnfvW",
    "outputId": "e769f6c3-7d81-44a2-9a01-11baa5189e4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test: Hello World\n"
     ]
    }
   ],
   "source": [
    "print (\"test: \" + test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "8XIynl-xnfva"
   },
   "source": [
    "**Kỳ vọng đầu ra**:\n",
    "test: Hello World"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "CHAU7ijRnfvb"
   },
   "source": [
    "<font color='blue'>\n",
    "**Hãy nhớ**:\n",
    "- Chạy cell bằng cách nhấn SHIFT+ENTER (hoặc \"Run cell\")\n",
    "- Chỉ viết code trong các vùng chỉ định dùng Python 3\n",
    "- Không sửa đổi code bên ngoài vùng chỉ định"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "agmiLlBxnfvb"
   },
   "source": [
    "## 1 - Tạo các hàm cơ bản với numpy ##\n",
    "\n",
    "Numpy là thư viện chính cho tính toán khoa học trong Python. Nó được duy trì bởi một cộng đồng lớn (www.numpy.org). Trong lab này, bạn sẽ học một số hàm numpy chính như np.exp, np.log và np.reshape. Bạn sẽ cần biết cách sử dụng các hàm này cho các bài tập trong tương lai.\n",
    "\n",
    "### 1.1 - sigmoid function, np.exp() ###\n",
    "\n",
    "Trước khi sử dụng np.exp(), bạn sẽ sử dụng math.exp() để triển khai hàm sigmoid. Sau đó, bạn hiểu tại sao np.exp() lại thích hợp hơn math.exp().\n",
    "\n",
    "**Task 2**: Xây dựng một hàm trả về giá trị sigmoid của số thực x. Sử dụng math.exp(x) cho hàm mũ.\n",
    "\n",
    "**Nhắc nhở**:\n",
    "$sigmoid (x) = \\frac{1}{1+e^ {- x}}$ đôi khi còn được gọi là hàm logistic. Đây là một hàm phi tuyến tính không chỉ được sử dụng trong Học máy (Hồi quy logistic) mà còn trong Học sâu (Deep Learning).\n",
    "\n",
    "<img src=\"images/Sigmoid.png\" style=\"width:500px;height:228px;\">\n",
    "\n",
    "Để tham chiếu đến một hàm thuộc một thư viện cụ thể, bạn có thể gọi nó bằng cách sử dụng package_name.functions(). Chạy đoạn code dưới đây để xem ví dụ với math.exp()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "H6IExurPnfvc"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def basic_sigmoid(x):\n",
    "    \"\"\"\n",
    "    Tính sigmoid của x.\n",
    "\n",
    "    Đối số:\n",
    "    x -- Số vô hướng\n",
    "\n",
    "    Trả về:\n",
    "    s -- sigmoid(x)\n",
    "    \"\"\"\n",
    "    \n",
    "    ### BẮT ĐẦU CODE Ở ĐÂY ### (≈ 1 dòng code)\n",
    "    s = 1/(1+math.exp(-x))\n",
    "    ### KẾT THÚC CODE Ở ĐÂY ###\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "i6ehIoQMnfvf",
    "outputId": "f1363ad3-d482-4b2b-f7f9-161c988cd89c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9525741268224334"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_sigmoid(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "x600oAoInfvi"
   },
   "source": [
    "**Kỳ vọng đầu ra**: \n",
    "<table style = \"width:40%\">\n",
    "    <tr>\n",
    "    <td>** basic_sigmoid(3) **</td> \n",
    "        <td>0.9525741268224334 </td> \n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "2LEJQT0anfvj"
   },
   "source": [
    "Trên thực tế, chúng ta hiếm khi sử dụng thư viện \"math\" trong học sâu vì đầu vào của các hàm là số thực. Trong học sâu, chúng ta chủ yếu sử dụng ma trận và vectơ. Đây là lý do tại sao numpy hữu ích hơn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Voeik2Rwnfvj",
    "outputId": "2ab5dfdc-bbaa-4198-fbdf-91bbbdb22993"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "bad operand type for unary -: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m### Một nguyên do chúng ta sử dụng \"numpy\" thay vì \"math\" trong DL ###\u001b[39;00m\n\u001b[1;32m      2\u001b[0m x \u001b[39m=\u001b[39m [\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m]\n\u001b[0;32m----> 3\u001b[0m basic_sigmoid(x)\n",
      "Cell \u001b[0;32mIn[3], line 15\u001b[0m, in \u001b[0;36mbasic_sigmoid\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mTính sigmoid của x.\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39ms -- sigmoid(x)\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39m### BẮT ĐẦU CODE Ở ĐÂY ### (≈ 1 dòng code)\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m s \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\u001b[39m/\u001b[39m(\u001b[39m1\u001b[39m\u001b[39m+\u001b[39mmath\u001b[39m.\u001b[39mexp(\u001b[39m-\u001b[39;49mx))\n\u001b[1;32m     16\u001b[0m \u001b[39m### KẾT THÚC CODE Ở ĐÂY ###\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39mreturn\u001b[39;00m s\n",
      "\u001b[0;31mTypeError\u001b[0m: bad operand type for unary -: 'list'"
     ]
    }
   ],
   "source": [
    "### Một nguyên do chúng ta sử dụng \"numpy\" thay vì \"math\" trong DL ###\n",
    "x = [1, 2, 3]\n",
    "basic_sigmoid(x) # các bạn sẽ thấy điều này gây ra lỗi khi chạy nó, vì x là một vectơ."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "yGKg7bjHnfvm"
   },
   "source": [
    "Thực tế, nếu $ x = (x_1, x_2, ..., x_n) $ là một vectơ hàng thì $ np.exp (x) $ sẽ áp dụng hàm mũ cho mọi phần tử của x. Do đó, kết quả đầu ra sẽ là: $ np.exp (x) = (e^{x_1}, e^{x_2}, ..., e^{x_n})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "cTuqrXTVnfvn",
    "outputId": "791e0b35-941e-42ac-e558-3f64ec23f725"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.71828183  7.3890561  20.08553692]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# ví dụ về np.exp\n",
    "x = np.array([1, 2, 3])\n",
    "print(np.exp(x)) # kết quả là (exp(1), exp(2), exp(3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "AZWQCeu8nfvq"
   },
   "source": [
    "Hơn nữa, nếu x là một vectơ thì phép toán Python như $ s = x + 3 $ hoặc $ s = \\frac {1} {x}$ sẽ xuất s dưới dạng một vectơ có cùng kích thước với x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "pd5HK3I5nfvq",
    "outputId": "a7e0832b-b562-4e23-eff0-6e4ff4ffde5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 5 6]\n"
     ]
    }
   ],
   "source": [
    "# ví dụ về phép toán vectơ\n",
    "x = np.array([1, 2, 3])\n",
    "print (x + 3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "U5gjzCGqnfvs"
   },
   "source": [
    "Bất kỳ lúc nào cần thêm thông tin về hàm numpy, hãy xem [tài liệu chính thức](https://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.exp.html). \n",
    "\n",
    "Chúng ta cũng có thể tạo một cell mới trong notebook và viết `np.exp?` (chẳng hạn) để truy cập nhanh vào tài liệu.\n",
    "\n",
    "**Task 3**: Thực thi hàm sigmoid dùng numpy. \n",
    "\n",
    "**Hướng dẫn**: x bây giờ có thể là một số thực, một vectơ hoặc một ma trận. Các cấu trúc dữ liệu chúng ta sử dụng trong numpy biểu diễn các dạng này (vectơ, ma trận,...) được gọi là mảng numpy. Chúng ta không cần phải biết thêm vào lúc này.\n",
    "$$ \\text{For } x \\in \\mathbb{R}^n \\text{,     } sigmoid(x) = sigmoid\\begin{pmatrix}\n",
    "    x_1  \\\\\n",
    "    x_2  \\\\\n",
    "    ...  \\\\\n",
    "    x_n  \\\\\n",
    "\\end{pmatrix} = \\begin{pmatrix}\n",
    "    \\frac{1}{1+e^{-x_1}}  \\\\\n",
    "    \\frac{1}{1+e^{-x_2}}  \\\\\n",
    "    ...  \\\\\n",
    "    \\frac{1}{1+e^{-x_n}}  \\\\\n",
    "\\end{pmatrix}\\tag{1} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "_6VTga3cnfvt"
   },
   "outputs": [],
   "source": [
    "import numpy as np # điều này có nghĩa là chúng ta có thể truy cập các hàm numpy bằng cách viết np.functions() thay vì numpy.functions()\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Tính sigmoid của x\n",
    "\n",
    "    Đối số:\n",
    "    x -- Mảng numpy hoặc vô hướng có bất kỳ kích thước nào \n",
    "\n",
    "    Trả về:\n",
    "    s -- sigmoid(x)\n",
    "    \"\"\"\n",
    "    \n",
    "    ### BẮT ĐẦU CODE Ở ĐÂY ### (≈ 1 dòng code)\n",
    "    s = 1/(1+np.exp(-x))\n",
    "    ### KẾT THÚC CODE Ở ĐÂY ###\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "7TKZVsrFnfvz",
    "outputId": "dbcbc0e5-d8ff-4d05-a3b8-7ccb0867f81a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.73105858, 0.88079708, 0.95257413])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([1, 2, 3])\n",
    "sigmoid(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "RoFcMN3Rnfv2"
   },
   "source": [
    "**Kỳ vọng đầu ra**: \n",
    "<table>\n",
    "    <tr> \n",
    "        <td> **sigmoid([1,2,3])**</td> \n",
    "        <td> array([ 0.73105858,  0.88079708,  0.95257413]) </td> \n",
    "    </tr>\n",
    "</table> \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "nRhiWuq8nfv3"
   },
   "source": [
    "### 1.2 - Sigmoid gradient\n",
    "\n",
    "Như đã thấy trong bài giảng, chúng ta sẽ cần tính gradient để tối ưu hóa các hàm mất mát bằng cách sử dụng phương pháp truyền ngược. Hãy mã hóa hàm gradient đầu tiên.\n",
    "\n",
    "**Task 4**: Triển khai hàm sigmoid_grad() để tính gradient của hàm sigmoid liên quan đến đầu vào x của nó. Công thức là:$$sigmoid\\_derivative(x) = \\sigma'(x) = \\sigma(x) (1 - \\sigma(x))\\tag{2}$$\n",
    "Chúng ta thường viết code hàm này theo hai bước:\n",
    "1. Đặt s là sigmoid của x. Bạn sẽ thấy hàm sigmoid(x) của mình hữu ích.\n",
    "2. Tính $\\sigma'(x) = s(1-s)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "1wh9LX7vnfv4"
   },
   "outputs": [],
   "source": [
    "def sigmoid_derivative(x):\n",
    "    \"\"\"\n",
    "    Tính gradient (cũng gọi là slope hoặc đạo hàm) của hàm sigmoid với đầu vào x của nó.\n",
    "    Lưu đầu ra của hàm sigmoid vào các biến rồi sử dụng nó để tính gradient\n",
    "    \n",
    "    Đối số:\n",
    "    x -- Mảng vô hướng hoặc mảng numpy\n",
    "\n",
    "    Trả về:\n",
    "    ds -- Gradient đã tính.\n",
    "    \"\"\"\n",
    "    \n",
    "    ### BẮT ĐẦU CODE Ở ĐÂY ### (≈ 2 dòng code)\n",
    "    s = 1/(1+np.exp(-x))\n",
    "    ds = s * (1-s)\n",
    "    ### KẾT THÚC CODE Ở ĐÂY ###\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "RWS_tgLJnfv6",
    "outputId": "c1006609-410d-4971-fb47-65652e2cfd78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid_derivative(x) = [0.19661193 0.10499359 0.04517666]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([1, 2, 3])\n",
    "print (\"sigmoid_derivative(x) = \" + str(sigmoid_derivative(x)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "5MtfW1bcnfv9"
   },
   "source": [
    "**Kỳ vọng đầu ra**: \n",
    "\n",
    "\n",
    "<table>\n",
    "    <tr> \n",
    "        <td> **sigmoid_derivative([1,2,3])**</td> \n",
    "        <td> [ 0.19661193  0.10499359  0.04517666] </td> \n",
    "    </tr>\n",
    "</table> \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "FZJQAXpvnfv-"
   },
   "source": [
    "### 1.3 - Định hình lại mảng ###\n",
    "\n",
    "Hai hàm numpy phổ biến được sử dụng trong học sâu là [np.shape](https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.shape.html) and [np.reshape()](https://docs.scipy.org/doc/numpy/reference/generated/numpy.reshape.html). \n",
    "- X.shape được sử dụng để lấy shape (kích thước) của ma trận/vectơ X.\n",
    "- X.reshape(...) được dùng để định hình lại X sang một số kích thước khác.\n",
    "\n",
    "Ví dụ, trong khoa học máy tính, hình ảnh được biểu diễn bằng mảng 3D có shape $(length, height, depth = 3)$. Tuy nhiên, khi đọc hình ảnh dưới dạng đầu vào của một thuật toán, bạn sẽ chuyển đổi nó thành một vectơ có shape $(length*height*3, 1)$. Nói cách khác, chúng ta \"triển khai\" hoặc định hình lại mảng 3D thành vectơ 1D.\n",
    "\n",
    "<img src=\"images/image2vector_kiank.png\" style=\"width:500px;height:300;\">\n",
    "\n",
    "**Task 5**: Triển khai `image2vector()` nhận đầu vào của shape (length, height, 3) và trả về một vectơ có shape (length\\*height * 3,1). Ví dụ: nếu bạn muốn định hình lại mảng v có shape (a, b, c) thành một vectơ có shape (a * b, c), chúng ta sẽ thực hiện:\n",
    "``` python\n",
    "v = v.reshape((v.shape[0]*v.shape[1], v.shape[2])) # v.shape[0] = a ; v.shape[1] = b ; v.shape[2] = c\n",
    "```\n",
    "- Vui lòng không mã hóa các kích thước của hình ảnh như một hằng số. Thay vào đó, hãy tra cứu số lượng bạn cần với `image.shape[0]`, v.v."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "e9wy3hBanfv-"
   },
   "outputs": [],
   "source": [
    "def image2vector(image):\n",
    "    \"\"\"\n",
    "    Đối số:\n",
    "    image -- mảng numpy có shape (length, height, depth)\n",
    "    \n",
    "    Trả về:\n",
    "    v -- vectơ có shape (length*height*depth, 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    ### BẮT ĐẦU CODE Ở ĐÂY ### (≈ 1 dòng code)\n",
    "    v = image.reshape(image.shape[0] * image.shape[1] * image.shape[2], 1)\n",
    "    ### KẾT THÚC CODE Ở ĐÂY ###\n",
    "    \n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "18cpElsRnfwA",
    "outputId": "7212d34c-74bb-4508-f821-4865b0cf5491"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image2vector(image) = [[0.67826139]\n",
      " [0.29380381]\n",
      " [0.90714982]\n",
      " [0.52835647]\n",
      " [0.4215251 ]\n",
      " [0.45017551]\n",
      " [0.92814219]\n",
      " [0.96677647]\n",
      " [0.85304703]\n",
      " [0.52351845]\n",
      " [0.19981397]\n",
      " [0.27417313]\n",
      " [0.60659855]\n",
      " [0.00533165]\n",
      " [0.10820313]\n",
      " [0.49978937]\n",
      " [0.34144279]\n",
      " [0.94630077]]\n"
     ]
    }
   ],
   "source": [
    "# Đây là mảng 3x3x2, thông thường hình ảnh sẽ là (num_px_x, num_px_y,3) trong đó 3 biểu diễn các giá trị RGB\n",
    "image = np.array([[[ 0.67826139,  0.29380381],\n",
    "        [ 0.90714982,  0.52835647],\n",
    "        [ 0.4215251 ,  0.45017551]],\n",
    "\n",
    "       [[ 0.92814219,  0.96677647],\n",
    "        [ 0.85304703,  0.52351845],\n",
    "        [ 0.19981397,  0.27417313]],\n",
    "\n",
    "       [[ 0.60659855,  0.00533165],\n",
    "        [ 0.10820313,  0.49978937],\n",
    "        [ 0.34144279,  0.94630077]]])\n",
    "\n",
    "print (\"image2vector(image) = \" + str(image2vector(image)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "IZEb9aP7nfwD"
   },
   "source": [
    "**Kỳ vọng đầu ra**: \n",
    "\n",
    "\n",
    "<table style=\"width:100%\">\n",
    "     <tr> \n",
    "       <td> **image2vector(image)** =\n",
    "        [[ 0.67826139] <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[ 0.29380381] <br>\n",
    " &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[ 0.90714982] <br>\n",
    " &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[ 0.52835647] <br>\n",
    " &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[ 0.4215251 &nbsp] <br>\n",
    " &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[ 0.45017551] <br>\n",
    " &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[ 0.92814219] <br>\n",
    " &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[ 0.96677647] <br>\n",
    " &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[ 0.85304703] <br>\n",
    " &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[ 0.52351845] <br>\n",
    " &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[ 0.19981397] <br>\n",
    " &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[ 0.27417313] <br>\n",
    " &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[ 0.60659855] <br>\n",
    " &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[ 0.00533165] <br>\n",
    " &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[ 0.10820313] <br>\n",
    " &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[ 0.49978937] <br>\n",
    " &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[ 0.34144279] <br>\n",
    " &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[ 0.94630077]]</td> \n",
    "     </tr>\n",
    "    \n",
    "   \n",
    "</table>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "WdxB2sX5nfwD"
   },
   "source": [
    "### 1.4 - Chuẩn hóa các hàng\n",
    "\n",
    "Một kỹ thuật phổ biến khác mà chúng ta sử dụng trong Machine Learning và Deep Learning là chuẩn hóa dữ liệu. Nó thường dẫn đến chất lượng tốt hơn bởi vì gradient descent hội tụ nhanh hơn sau khi chuẩn hóa. Ở đây, theo cách chuẩn hóa, chúng ta muốn thay đổi x thành $\\frac {x} {\\| x \\|}$ (chia mỗi vectơ hàng của x cho chuẩn của nó).\n",
    "\n",
    "Ví dụ: nếu $$x = \n",
    "\\begin{bmatrix}\n",
    "    0 & 3 & 4 \\\\\n",
    "    2 & 6 & 4 \\\\\n",
    "\\end{bmatrix}\\tag{3}$$ thì $$\\| x\\| = np.linalg.norm(x, axis = 1, keepdims = True) = \\begin{bmatrix}\n",
    "    5 \\\\\n",
    "    \\sqrt{56} \\\\\n",
    "\\end{bmatrix}\\tag{4} $$và        $$ x\\_normalized = \\frac{x}{\\| x\\|} = \\begin{bmatrix}\n",
    "    0 & \\frac{3}{5} & \\frac{4}{5} \\\\\n",
    "    \\frac{2}{\\sqrt{56}} & \\frac{6}{\\sqrt{56}} & \\frac{4}{\\sqrt{56}} \\\\\n",
    "\\end{bmatrix}\\tag{5}$$ Lưu ý rằng chúng ta có thể chia các ma trận có kích thước khác nhau và nó vẫn hoạt động tốt: đây được gọi là broadcasting (truyền phát) và chúng ta sẽ tìm hiểu về nó sau.\n",
    "\n",
    "\n",
    "**Task 6**: Triển khai normalizeRows() để chuẩn hóa các hàng của ma trận. Sau khi áp dụng hàm này cho ma trận đầu vào x, mỗi hàng của x phải là một vectơ có độ dài đơn vị (nghĩa là độ dài 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "cD-oUbtznfwE"
   },
   "outputs": [],
   "source": [
    "def normalizeRows(x):\n",
    "    \"\"\"\n",
    "    Triển khai một hàm chuẩn hóa từng hàng của ma trận x (có độ dài đơn vị)\n",
    "    \n",
    "    Đối số:\n",
    "    x -- Ma trận numpy có shape (n, m)\n",
    "    \n",
    "    Trả về:\n",
    "    x -- Ma trận numpy đã chuẩn hóa (theo hàng). Chúng ta được phép sửa x.\n",
    "    \"\"\"\n",
    "    \n",
    "    ### BẮT ĐẦU CODE Ở ĐÂY ### (≈ 2 dòng code)\n",
    "    # Tính x_norm là chuẩn 2 của x. Sử dụng np.linalg.norm(..., ord = 2, axis = ..., keepdims = True)\n",
    "    x_norm = np.linalg.norm(x, ord=2, axis=1, keepdims=True)\n",
    "    # Chia x cho chuẩn của nó.\n",
    "    x = x/x_norm\n",
    "    ### KẾT THÚC CODE Ở ĐÂY ###\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WYD8tSVVnfwF",
    "outputId": "53999fd8-d1de-41aa-f200-7d96777dcc8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizeRows(x) = [[0.         0.6        0.8       ]\n",
      " [0.13736056 0.82416338 0.54944226]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([\n",
    "    [0, 3, 4],\n",
    "    [1, 6, 4]])\n",
    "print(\"normalizeRows(x) = \" + str(normalizeRows(x)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "ipsZBoTLnfwI"
   },
   "source": [
    "**Kỳ vọng đầu ra**: \n",
    "\n",
    "<table style=\"width:60%\">\n",
    "\n",
    "     <tr> \n",
    "       <td> **normalizeRows(x)** </td> \n",
    "       <td> [[ 0.          0.6         0.8       ]\n",
    " [ 0.13736056  0.82416338  0.54944226]]</td> \n",
    "     </tr>\n",
    "    \n",
    "   \n",
    "</table>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "TGsQ2dhVnfwJ"
   },
   "source": [
    "**Lưu ý**:\n",
    "Trong normalizeRows(), chúng ta có thể thử in các shape của x_norm và x, sau đó chạy lại đánh giá. Các bạn sẽ nhận ra rằng chúng có các hình dạng khác nhau. Điều này là bình thường khi x_norm lấy chuẩn của mỗi hàng x. Vì vậy, x_norm có cùng số hàng nhưng chỉ có 1 cột. Vậy nó hoạt động như thế nào khi chia x cho x_norm? Đây được gọi là broadcasting và chúng ta sẽ nói về nó ngay bây giờ!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "yn45aHHXnfwJ"
   },
   "source": [
    "### 1.5 - Broadcasting (Truyền phát) và hàm softmax ####\n",
    "Một khái niệm rất quan trọng cần hiểu trong numpy là \"broadcasting\" (truyền phát). Nó rất hữu ích khi thực hiện các phép toán giữa các mảng có hình dạng khác nhau. Để biết chi tiết đầy đủ về broadcasting, bạn có thể đọc [tài liệu broadcasting] chính thức (http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "WQOjOT04nfwJ"
   },
   "source": [
    "**Task 7**: Thực hiện một hàm softmax bằng cách sử dụng numpy. Chúng ta có thể coi softmax như một hàm chuẩn hóa được sử dụng khi thuật toán cần phân loại hai hoặc nhiều lớp. Chúng ta sẽ tìm hiểu thêm về softmax trong các bài học tiếp theo.\n",
    "\n",
    "**Hướng dẫn**:\n",
    "- $ \\text{cho } x \\in \\mathbb{R}^{1\\times n} \\text{,     } softmax(x) = softmax(\\begin{bmatrix}\n",
    "    x_1  &&\n",
    "    x_2 &&\n",
    "    ...  &&\n",
    "    x_n  \n",
    "\\end{bmatrix}) = \\begin{bmatrix}\n",
    "     \\frac{e^{x_1}}{\\sum_{j}e^{x_j}}  &&\n",
    "    \\frac{e^{x_2}}{\\sum_{j}e^{x_j}}  &&\n",
    "    ...  &&\n",
    "    \\frac{e^{x_n}}{\\sum_{j}e^{x_j}} \n",
    "\\end{bmatrix} $ \n",
    "\n",
    "- $\\text{cho ma trận } x \\in \\mathbb{R}^{m \\times n} \\text{,  $x_{ij}$ ánh xạ tới phần tử trong hàng thứ $i^{th}$ và cột thứ $j^{th}$ của $x$, ta được: }$  $$softmax(x) = softmax\\begin{bmatrix}\n",
    "    x_{11} & x_{12} & x_{13} & \\dots  & x_{1n} \\\\\n",
    "    x_{21} & x_{22} & x_{23} & \\dots  & x_{2n} \\\\\n",
    "    \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    x_{m1} & x_{m2} & x_{m3} & \\dots  & x_{mn}\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "    \\frac{e^{x_{11}}}{\\sum_{j}e^{x_{1j}}} & \\frac{e^{x_{12}}}{\\sum_{j}e^{x_{1j}}} & \\frac{e^{x_{13}}}{\\sum_{j}e^{x_{1j}}} & \\dots  & \\frac{e^{x_{1n}}}{\\sum_{j}e^{x_{1j}}} \\\\\n",
    "    \\frac{e^{x_{21}}}{\\sum_{j}e^{x_{2j}}} & \\frac{e^{x_{22}}}{\\sum_{j}e^{x_{2j}}} & \\frac{e^{x_{23}}}{\\sum_{j}e^{x_{2j}}} & \\dots  & \\frac{e^{x_{2n}}}{\\sum_{j}e^{x_{2j}}} \\\\\n",
    "    \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    \\frac{e^{x_{m1}}}{\\sum_{j}e^{x_{mj}}} & \\frac{e^{x_{m2}}}{\\sum_{j}e^{x_{mj}}} & \\frac{e^{x_{m3}}}{\\sum_{j}e^{x_{mj}}} & \\dots  & \\frac{e^{x_{mn}}}{\\sum_{j}e^{x_{mj}}}\n",
    "\\end{bmatrix} = \\begin{pmatrix}\n",
    "    softmax\\text{(hàng thứ nhất của x)}  \\\\\n",
    "    softmax\\text{(hàng thứ hai của x)} \\\\\n",
    "    ...  \\\\\n",
    "    softmax\\text{(hàng cuối của x)} \\\\\n",
    "\\end{pmatrix} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "OCHr_d6JnfwK"
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    \"\"\"Tính softmax cho từng hàng của đầu vào x.\n",
    "\n",
    "    Code của chúng ta phải hoạt động cho vectơ hàng và cả cho ma trận shape (n, m).\n",
    "\n",
    "    Đối số:\n",
    "    x -- Ma trận numpy có shape (n,m)\n",
    "\n",
    "    Trả về:\n",
    "    s -- Ma trận numpy bằng với softmax của x, của shape (n,m)\n",
    "    \"\"\"\n",
    "    \n",
    "    ### BẮT ĐẦU CODE Ở ĐÂY ### (≈ 3 dòng code)\n",
    "    # Áp dụng element-wise exp() vào x. Sử dụng np.exp(...).\n",
    "    x_exp = np.exp(x)\n",
    "\n",
    "\n",
    "    # Tạo vetơ x_sum tính tổng từng hàng của x_exp. Sử dụng np.sum(..., axis = 1, keepdims = True).\n",
    "    x_sum = np.sum(x_exp, axis=1, keepdims=True)\n",
    "    # Tính softmax(x) bằng cách chia  x_exp cho x_sum. Nó sẽ được tự động hóa bằng numpy broadcasting.\n",
    "    s = x_exp / x_sum\n",
    "    ### KẾT THÚC CODE Ở ĐÂY ###\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "R5mEZP7HnfwL",
    "outputId": "48ed6bd8-78bf-49a6-b502-c9f47d7985f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax(x) = [[9.80897665e-01 8.94462891e-04 1.79657674e-02 1.21052389e-04\n",
      "  1.21052389e-04]\n",
      " [8.78679856e-01 1.18916387e-01 8.01252314e-04 8.01252314e-04\n",
      "  8.01252314e-04]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([\n",
    "    [9, 2, 5, 0, 0],\n",
    "    [7, 5, 0, 0 ,0]])\n",
    "print(\"softmax(x) = \" + str(softmax(x)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "SzxjvD7knfwN"
   },
   "source": [
    "**Kỳ vọng đầu ra**:\n",
    "\n",
    "<table style=\"width:60%\">\n",
    "\n",
    "     <tr> \n",
    "       <td> **softmax(x)** </td> \n",
    "       <td> [[  9.80897665e-01   8.94462891e-04   1.79657674e-02   1.21052389e-04\n",
    "    1.21052389e-04]\n",
    " [  8.78679856e-01   1.18916387e-01   8.01252314e-04   8.01252314e-04\n",
    "    8.01252314e-04]]</td> \n",
    "     </tr>\n",
    "</table>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "qyyp5Z4snfwN"
   },
   "source": [
    "**Lưu ý**:\n",
    "- Nếu in shape của x_exp, x_sum và s ở trên và chạy lại cell đánh giá, chúng ta sẽ thấy rằng x_sum có shape (2,1) trong khi x_exp và s có shape (2,5). **x_exp/x_sum** hoạt động nhờ Python broadcasting.\n",
    "\n",
    "Xin chúc mừng! Bây giờ các bạn đã hiểu khá tốt về numpy Python và đã triển khai một số hàm hữu ích mà chúng ta sẽ sử dụng trong Deep learning."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "0dS4WXo0nfwO"
   },
   "source": [
    "<font color='blue'>\n",
    "\n",
    "**Những điều cần nhớ:**\n",
    "- np.exp(x) hoạt động với bất kỳ np.array x nào và áp dụng hàm mũ cho mọi tọa độ\n",
    "- hàm sigmoid và gradient của nó\n",
    "- image2vector thường được sử dụng trong deep learning\n",
    "- np.reshape được sử dụng rộng rãi. Trong tương lai, các bạn sẽ thấy rằng việc giữ thẳng kích thước ma trận/vectơ sẽ giúp loại bỏ rất nhiều lỗi\n",
    "- numpy có các hàm tích hợp hiệu quả\n",
    "- broadcasting cực kỳ hữu ích"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "UV1tMN6jnfwO"
   },
   "source": [
    "## 2) Vectơ hóa"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "wPlvKU_KnfwO"
   },
   "source": [
    "\n",
    "Trong deep learning, chúng ta phải xử lý các tập dữ liệu rất lớn. Do đó, một hàm không tối ưu về mặt tính toán có thể trở thành một nút thắt lớn trong thuật toán và có thể khiến mô hình mất nhiều thời gian để chạy. Để đảm bảo code hiệu quả về mặt tính toán, hãy sử dụng vectơ hóa. Ví dụ: cố gắng phân biệt sự khác biệt giữa các cách triển khai sau đây của tích vô hướng/tích ngoài/elementwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "X2raElv3nfwP",
    "outputId": "1f61d234-b46e-4117-cfce-17a0f160244c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dot = 278\n",
      " ----- Computation time = 0.11231200000005881ms\n",
      "outer = [[81. 18. 18. 81.  0. 81. 18. 45.  0.  0. 81. 18. 45.  0.  0.]\n",
      " [18.  4.  4. 18.  0. 18.  4. 10.  0.  0. 18.  4. 10.  0.  0.]\n",
      " [45. 10. 10. 45.  0. 45. 10. 25.  0.  0. 45. 10. 25.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [63. 14. 14. 63.  0. 63. 14. 35.  0.  0. 63. 14. 35.  0.  0.]\n",
      " [45. 10. 10. 45.  0. 45. 10. 25.  0.  0. 45. 10. 25.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [81. 18. 18. 81.  0. 81. 18. 45.  0.  0. 81. 18. 45.  0.  0.]\n",
      " [18.  4.  4. 18.  0. 18.  4. 10.  0.  0. 18.  4. 10.  0.  0.]\n",
      " [45. 10. 10. 45.  0. 45. 10. 25.  0.  0. 45. 10. 25.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n",
      " ----- Computation time = 0.15125799999993195ms\n",
      "elementwise multiplication = [81.  4. 10.  0.  0. 63. 10.  0.  0.  0. 81.  4. 25.  0.  0.]\n",
      " ----- Computation time = 0.05743099999999668ms\n",
      "gdot = [24.78942909 23.03162455 26.55368018]\n",
      " ----- Computation time = 0.07600199999990842ms\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "x1 = [9, 2, 5, 0, 0, 7, 5, 0, 0, 0, 9, 2, 5, 0, 0]\n",
    "x2 = [9, 2, 2, 9, 0, 9, 2, 5, 0, 0, 9, 2, 5, 0, 0]\n",
    "\n",
    "### TÍCH VÔ HƯỚNG CỦA TRIỂN KHAI VECTƠ ###\n",
    "tic = time.process_time()\n",
    "dot = 0\n",
    "for i in range(len(x1)):\n",
    "    dot+= x1[i]*x2[i]\n",
    "toc = time.process_time()\n",
    "print (\"dot = \" + str(dot) + \"\\n ----- Computation time = \" + str(1000*(toc - tic)) + \"ms\")\n",
    "\n",
    "### TÍCH NGOÀI CỦA TRIỂN KHAI VECTƠ ###\n",
    "tic = time.process_time()\n",
    "outer = np.zeros((len(x1),len(x2))) # we create a len(x1)*len(x2) matrix with only zeros\n",
    "for i in range(len(x1)):\n",
    "    for j in range(len(x2)):\n",
    "        outer[i,j] = x1[i]*x2[j]\n",
    "toc = time.process_time()\n",
    "print (\"outer = \" + str(outer) + \"\\n ----- Computation time = \" + str(1000*(toc - tic)) + \"ms\")\n",
    "\n",
    "### TRIỂN KHAI ELEMENTWISE ###\n",
    "tic = time.process_time()\n",
    "mul = np.zeros(len(x1))\n",
    "for i in range(len(x1)):\n",
    "    mul[i] = x1[i]*x2[i]\n",
    "toc = time.process_time()\n",
    "print (\"elementwise multiplication = \" + str(mul) + \"\\n ----- Computation time = \" + str(1000*(toc - tic)) + \"ms\")\n",
    "\n",
    "### TRIỂN KHAI TÍCH VÔ HƯỚNG TỔNG QUÁT ###\n",
    "W = np.random.rand(3,len(x1)) # Mảng numpy 3*len(x1) ngẫu nhiên\n",
    "tic = time.process_time()\n",
    "gdot = np.zeros(W.shape[0])\n",
    "for i in range(W.shape[0]):\n",
    "    for j in range(len(x1)):\n",
    "        gdot[i] += W[i,j]*x1[j]\n",
    "toc = time.process_time()\n",
    "print (\"gdot = \" + str(gdot) + \"\\n ----- Computation time = \" + str(1000*(toc - tic)) + \"ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "QsHOTMwfnfwQ",
    "outputId": "2b1df529-12c0-44d0-ebb5-a026a3386212"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dot = 278\n",
      " ----- Computation time = 0.06752099999995931ms\n",
      "outer = [[81 18 18 81  0 81 18 45  0  0 81 18 45  0  0]\n",
      " [18  4  4 18  0 18  4 10  0  0 18  4 10  0  0]\n",
      " [45 10 10 45  0 45 10 25  0  0 45 10 25  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [63 14 14 63  0 63 14 35  0  0 63 14 35  0  0]\n",
      " [45 10 10 45  0 45 10 25  0  0 45 10 25  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [81 18 18 81  0 81 18 45  0  0 81 18 45  0  0]\n",
      " [18  4  4 18  0 18  4 10  0  0 18  4 10  0  0]\n",
      " [45 10 10 45  0 45 10 25  0  0 45 10 25  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      " ----- Computation time = 0.0541269999999594ms\n",
      "elementwise multiplication = [81  4 10  0  0 63 10  0  0  0 81  4 25  0  0]\n",
      " ----- Computation time = 0.03317700000005086ms\n",
      "gdot = [24.78942909 23.03162455 26.55368018]\n",
      " ----- Computation time = 0.4428939999999715ms\n"
     ]
    }
   ],
   "source": [
    "x1 = [9, 2, 5, 0, 0, 7, 5, 0, 0, 0, 9, 2, 5, 0, 0]\n",
    "x2 = [9, 2, 2, 9, 0, 9, 2, 5, 0, 0, 9, 2, 5, 0, 0]\n",
    "\n",
    "### TÍCH VÔ HƯỚNG VECTƠ HÓA CỦA VECTƠ ###\n",
    "tic = time.process_time()\n",
    "dot = np.dot(x1,x2)\n",
    "toc = time.process_time()\n",
    "print (\"dot = \" + str(dot) + \"\\n ----- Computation time = \" + str(1000*(toc - tic)) + \"ms\")\n",
    "\n",
    "### TÍCH NGOÀI VECTƠ HÓA ###\n",
    "tic = time.process_time()\n",
    "outer = np.outer(x1,x2)\n",
    "toc = time.process_time()\n",
    "print (\"outer = \" + str(outer) + \"\\n ----- Computation time = \" + str(1000*(toc - tic)) + \"ms\")\n",
    "\n",
    "### PHÉP NHÂN ELEMENTWISE VECTƠ HÓA  ###\n",
    "tic = time.process_time()\n",
    "mul = np.multiply(x1,x2)\n",
    "toc = time.process_time()\n",
    "print (\"elementwise multiplication = \" + str(mul) + \"\\n ----- Computation time = \" + str(1000*(toc - tic)) + \"ms\")\n",
    "\n",
    "### TÍCH VÔ HƯỚNG TỔNG QUÁT VECTƠ HÓA ###\n",
    "tic = time.process_time()\n",
    "dot = np.dot(W,x1)\n",
    "toc = time.process_time()\n",
    "print (\"gdot = \" + str(dot) + \"\\n ----- Computation time = \" + str(1000*(toc - tic)) + \"ms\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "FpVb7BfxnfwS"
   },
   "source": [
    "Như các bạn thấy, việc triển khai vectơ hóa nhanh và hiệu quả hơn nhiều. Đối với các vectơ/ma trận lớn hơn, sự khác biệt về thời gian chạy thậm chí còn lớn hơn.\n",
    "\n",
    "**Lưu ý** rằng `np.dot()` thực hiện phép nhân ma trận-ma trận hoặc ma trận-vectơ. Điều này khác với toán tử `np.multiply()` và `*` (tương đương với `.*` trong Matlab/Octave), thực hiện phép nhân từng phần tử của 2 ma trận cùng chiều."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Yb_-hjmenfwS"
   },
   "source": [
    "### 2.1 Thực hiện các hàm mất mát L1 và L2\n",
    "\n",
    "**Task 8**: Thực hiện phiên bản vectơ hóa numpy của hàm mất mát L1. Chúng ta có thể thấy hàm abs(x) (giá trị tuyệt đối của x) hữu ích.\n",
    "\n",
    "**Nhắc nhở**:\n",
    "- Hàm mất mát được sử dụng để đánh giá chất lượng mô hình. Giá trị mất mát càng lớn thì các dự đoán ($\\hat {y} $) càng khác với giá trị thực ($y$). Trong deep learning, chúng ta sử dụng các thuật toán tối ưu hóa như Gradient Descent để huấn luyện mô hình và để giảm thiểu chi phí.\n",
    "- Giá trị mất mát L1 được xác định như sau:\n",
    "$$\\begin{align*} & L_1(\\hat{y}, y) = \\sum_{i=0}^m|y^{(i)} - \\hat{y}^{(i)}| \\end{align*}\\tag{6}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "_3GTw9gQnfwS"
   },
   "outputs": [],
   "source": [
    "def L1(yhat, y):\n",
    "    \"\"\"\n",
    "    Đối số:\n",
    "    yhat -- vectơ có kích thước (nhãn dự đoán)\n",
    "    y -- vectơ có kích thước (nhãn đúng)\n",
    "    \n",
    "    Trả về:\n",
    "    loss -- giá trị của hàm mất mát L1 đã xác định ở trên \n",
    "    \"\"\"\n",
    "    \n",
    "    ### BẮT ĐẦU CODE Ở ĐÂY ### (≈ 1 dòng code)\n",
    "    loss = np.sum(np.abs(y - yhat))\n",
    "    ### KẾT THÚC CODE Ở ĐÂY ###\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "uzrOQ3axnfwV",
    "outputId": "de53d655-1be2-430d-9d92-a92cc90bcebb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 = 1.1\n"
     ]
    }
   ],
   "source": [
    "yhat = np.array([.9, 0.2, 0.1, .4, .9])\n",
    "y = np.array([1, 0, 0, 1, 1])\n",
    "print(\"L1 = \" + str(L1(yhat,y)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "5o47CxuQnfwY"
   },
   "source": [
    "**Kỳ vọng đầu ra**:\n",
    "\n",
    "<table style=\"width:20%\">\n",
    "\n",
    "     <tr> \n",
    "       <td> **L1** </td> \n",
    "       <td> 1.1 </td> \n",
    "     </tr>\n",
    "</table>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "2zSr1VhWnfwY"
   },
   "source": [
    "**Task 9**: Thực hiện phiên bản vectơ hóa numpy của giá trị mất mát L2. Có một số cách để thực hiện L2 nhưng các bạn sẽ thấy hàm np.dot() hữu ích. Xin nhắc lại, nếu $x = [x_1, x_2, ..., x_n]$, thì `np.dot(x,x)` = $\\sum_{j=0}^n x_j^{2}$. \n",
    "\n",
    "- L2 được xác định như sau $$\\begin{align*} & L_2(\\hat{y},y) = \\sum_{i=0}^m(y^{(i)} - \\hat{y}^{(i)})^2 \\end{align*}\\tag{7}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "2e6_zQN7nfwZ"
   },
   "outputs": [],
   "source": [
    "def L2(yhat, y):\n",
    "    \"\"\"\n",
    "    Đối số:\n",
    "    yhat -- vectơ có kích thước (nhãn dự đoán)\n",
    "    y -- vectơ có kích thước (nhãn đúng)\n",
    "    \n",
    "    Trả về:\n",
    "    loss -- giá trị của hàm mất mát L2 đã xác định ở trên\n",
    "    \"\"\"\n",
    "    \n",
    "    ### BẮT ĐẦU CODE Ở ĐÂY ### (≈ 1 dòng code)\n",
    "    loss = np.sum(np.power(y-yhat, 2))\n",
    "    ### KẾT THÚC CODE Ở ĐÂY ###\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "YF-2bBXqnfwa",
    "outputId": "a82a8195-29d9-4ffd-9107-b09403503bc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 = 0.43\n"
     ]
    }
   ],
   "source": [
    "yhat = np.array([.9, 0.2, 0.1, .4, .9])\n",
    "y = np.array([1, 0, 0, 1, 1])\n",
    "print(\"L2 = \" + str(L2(yhat,y)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "xWbFk0klnfwc"
   },
   "source": [
    "**Kỳ vọng đầu ra**: \n",
    "<table style=\"width:20%\">\n",
    "     <tr> \n",
    "       <td> **L2** </td> \n",
    "       <td> 0.43 </td> \n",
    "     </tr>\n",
    "</table>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "VPK3KRs7nfwd"
   },
   "source": [
    "Chúc mừng các bạn đã hoàn thành bài tập này. Chúng tôi hy vọng rằng bài tập khởi động nhỏ này sẽ giúp ích cho các bạn trong những bài tập sắp tới, trở nên hào hứng và thú vị hơn!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "V0TjDSkWnfwd"
   },
   "source": [
    "<font color='blue'>\n",
    "\n",
    "**Những điều cần nhớ:**\n",
    "- Vectơ hóa là rất quan trọng trong deep learning. Nó giúp tính toán chất lượng và rõ ràng hơn.\n",
    "- Chúng ta đã xem lại hàm mất mát L1 và L2.\n",
    "- Chúng ta đã quen với nhiều hàm numpy như np.sum, np.dot, np.multiply, np.maximum,..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2VceWrtG07Mo"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "[VN]Lab_2_1_Numpy và Vectơ hóa trong Python.ipynb",
   "provenance": []
  },
  "coursera": {
   "course_slug": "neural-networks-deep-learning",
   "graded_item_id": "XHpfv",
   "launcher_item_id": "Zh0CU"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

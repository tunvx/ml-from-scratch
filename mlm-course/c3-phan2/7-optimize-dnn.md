# Tối ưu mô hình DNN

## 1. Mini-batch GD


- **Video: [Mini-batch gradient descent](https://www.coursera.org/learn/deep-neural-network/lecture/qcogH/mini-batch-gradient-descent)**

- **Video: [Hiểu rõ hơn về mini-batch gradient descent](https://www.coursera.org/learn/deep-neural-network/lecture/lBXu8/understanding-mini-batch-gradient-descent)**



## 2. Momentumn (động lượng)



- **Video: [Exponentially weighted averages (Trung bình trọng số theo cấp số nhân)](https://www.coursera.org/learn/deep-neural-network/lecture/duStO/exponentially-weighted-averages)**

- **Video: [Hiểu rõ hơn về exponentially weighted averages](https://www.coursera.org/learn/deep-neural-network/lecture/Ud7t0/understanding-exponentially-weighted-averages)**


- **Video: [Điều chỉnh độ lệch trong exponentially weighted averages](https://www.coursera.org/learn/deep-neural-network/lecture/XjuhD/bias-correction-in-exponentially-weighted-averages)**

- **Video: [Gradient descent theo momentum](https://www.coursera.org/learn/deep-neural-network/lecture/y0m1f/gradient-descent-with-momentum)**



## 3. RMSprop và Adam


- **Video: [RMSprop](https://www.coursera.org/learn/deep-neural-network/lecture/BhJlm/rmsprop)**

- **Video: [Phương pháp tối ưu Adam](https://www.coursera.org/learn/deep-neural-network/lecture/w9VCZ/adam-optimization-algorithm)**



## 4. Tốc độ học

- **Video: [Learning rate decay (Sự suy giảm tốc độ học)](https://www.coursera.org/learn/deep-neural-network/lecture/hjgIA/learning-rate-decay)**


- **Video: [Vấn đề tối ưu địa phương/cục bộ](https://www.coursera.org/learn/deep-neural-network/lecture/RFANA/the-problem-of-local-optima)**

## Labs

[Lab 6: Các thuật toán tối ưu trong DNN](labs/Lab6.zip)